{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "input_data = np.load(open('./data/train_input.npy', 'rb'))\n",
    "out_data = np.load(open('./data/train_label.npy', 'rb'))\n",
    "\n",
    "prepro_config=None\n",
    "\n",
    "with open('./data/data_configs.json','r') as f :\n",
    "    prepro_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED=13371447\n",
    "TEST_SPLIT=0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, out_data, test_size=TEST_SPLIT,\n",
    "                                                   random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 입력 함수\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "def mapping_fn(X,Y):\n",
    "    inputs, labels = {'x':X}, Y\n",
    "    return inputs, labels\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \n",
    "    #둘을 묶어 조각으로 만듬\n",
    "    dataset = dataset.shuffle(buffer_size=len(X_train))\n",
    "    #임의의 순서대로 데이터가 나옴, 데이터 전체길이를 넣어주면됨\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    #배치사이즈를 지정함으로 써 한번에 16개씩 나옴\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    #하나의 딕셔너리로 묶기위해서\n",
    "    dataset = dataset.repeat(count=NUM_EPOCHS)\n",
    "    #데이터를 반복해서 총 3번 불러옴\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    #데이터를 하나씩 사용할 수 있게 함\n",
    "    \n",
    "    return iterator.get_next() # 데이터가 하나씩 나옴\n",
    "    \n",
    "    \n",
    "    \n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    dataset = dataset.batch(len(X_test))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 하이퍼파라미터 정의\n",
    "VOCAB_SIZE = prepro_config['vocab_size']\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "HIDDEN_STATE_DIM = 150\n",
    "DENSE_FEATURE_DIM = 150\n",
    "\n",
    "learning_rate = 0.001  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    #모델 구현\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    embedding_layer = tf.keras.layers.Embedding(VOCAB_SIZE, WORD_EMBEDDING_DIM)(features['x'])\n",
    "    #features['x']는 파이썬 딕셔너리 형태\n",
    "    \n",
    "    embedding_layer = tf.keras.layers.Dropout(0.2)(embedding_layer)\n",
    "    \n",
    "    rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [HIDDEN_STATE_DIM, HIDDEN_STATE_DIM]]\n",
    "    #심층 순환 신경망 모델은 LSTM이며 이를 객체화 함, Cell객체 여러개 생성해 리스트로 만들어 주며 hidden state의 차원만 정의\n",
    "    #LSTMCell을 쌓게 되면 이를 하나의 MultiRNN으로 묶음-> wrapping\n",
    "    \n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    #MultiRNNCell을 생성해 LSTM신경망을 구현\n",
    "    \n",
    "    #네트워크와 임베딩 벡터를 연산하기위해 dynamic_rnn 함수 선언\n",
    "    #이는 for문없이 자동으로 순환 신경망을 만들어 주는 역할\n",
    "    #cell=순환신경망객체 , input=입력값(임베딩레이어) , dtype=데이터타입 설정\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell = multi_rnn_cell,\n",
    "                                      inputs = embedding_layer,\n",
    "                                      dtype = tf.float32)\n",
    "    \n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(0.2)(outputs)\n",
    "    #출력값을 Dense에 적용\n",
    "    #LSTM신경망의 마지막 출력값에 넣어준다\n",
    "    #출력값에 [:,-1,:]로 마지막 값만 뽑은 후 적용\n",
    "    #활성화 함수는 하이퍼블릭 탄젠트(hyperbolic tangent)\n",
    "    hidden_layer = tf.keras.layers.Dense(DENSE_FEATURE_DIM, activation=tf.nn.tanh)(outputs[:,-1,:])\n",
    "    hidden_layer = tf.keras.layers.Dropout(0.2)(hidden_layer)\n",
    "    \n",
    "    #최종적으로 1dim 의 output만 할 수 있도록 dense layer를 활용해 차원 변환\n",
    "    #감정이 긍정인지 부정인지 판단 할 수 있도록 출력값을 하나로 만듬, 입력 벡터에 대한 차원 수 를 바꿈\n",
    "    #이 역할을 Dense가 함\n",
    "    logits = tf.keras.layers.Dense(1)(hidden_layer) #logit은 출력값\n",
    "    logits = tf.squeeze(logits, axis=-1)\n",
    "    \n",
    "    \n",
    "    #모델 예측을 위한 구현\n",
    "    #모델 출력값을 0~1 사이값으로 정의하기 위해 sigmoid함수 활용\n",
    "    if PREDICT:\n",
    "        pred = tf.nn.sigmoid(logits)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions={'sentiment':tf.round(pred)}) #예측값 입력\n",
    "    \n",
    "    \n",
    "    #모델 학습을 위한 구현\n",
    "    #모델에서 구현한 값과 정답 라벨을 가지고 손실(loss)값을 구해 Adam Optimizer을 활용해 모델 파라미터 최적화\n",
    "    #로스값은 logits과 정답인 labels변수를 가지고 구함\n",
    "    #logits값이 스케일을 맞춰 두지 않았지만 sigmoid_cross_entropy를 통해 손실값을 구할 수 있음\n",
    "    loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "    \n",
    "    #로스값 구한 후 파라미터를 최적화하고자 경사도 하강법을 진행한다\n",
    "    #경사도 하강법인 AdamOptimizer객체를 생성할때 학습률을 입력, 또한 global_step값을 넣어야한다.\n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step() #현재 global_step값 얻음\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode, train_op = train_op, loss=loss) \n",
    "    #estimatorSpec에서 학습 연산과 손실값이 필요, 각 모드에 따라 필요한 입력값 다름\n",
    "    #학습의 경우 학습연산과 손실값 필요\n",
    "        \n",
    "    #모델 평가를 위한 구현\n",
    "    #감정 예측값이 정답 라벨과 얼마나 일치하는지 정확도를 봄\n",
    "    if EVAL:\n",
    "        pred = tf.nn.sigmoid(logits)\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(pred))#정확도\n",
    "        eval_metric_ops = {'acc':accuracy}\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops) #평가 연산 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './checkpoint/rnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A2FE9BD2C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "est = tf.estimator.Estimator(model_fn, model_dir='./checkpoint/rnn')\n",
    "#est객체 생성시 인자로 작성한 모델 함수 이름을 입력한다.\n",
    "#생성한 객체를 통해 학습과 평가, 예측 등의 실행이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From <ipython-input-4-3b143d3ad0cc>:20: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-6-1601f179856b>:13: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-1601f179856b>:17: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-1601f179856b>:25: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/rnn\\model.ckpt-14081\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 14081 into ./checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0009962221, step = 14082\n",
      "INFO:tensorflow:global_step/sec: 4.44386\n",
      "INFO:tensorflow:loss = 0.0019440004, step = 14182 (22.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.67876\n",
      "INFO:tensorflow:loss = 0.0014109456, step = 14282 (21.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.94604\n",
      "INFO:tensorflow:loss = 0.011926787, step = 14382 (20.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.67388\n",
      "INFO:tensorflow:loss = 0.0010684463, step = 14482 (21.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.84676\n",
      "INFO:tensorflow:loss = 0.005626025, step = 14582 (20.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.59465\n",
      "INFO:tensorflow:loss = 0.00044443866, step = 14682 (21.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.88553\n",
      "INFO:tensorflow:loss = 0.00036687197, step = 14782 (20.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.78634\n",
      "INFO:tensorflow:loss = 0.00026432634, step = 14882 (20.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.82705\n",
      "INFO:tensorflow:loss = 0.00027337583, step = 14982 (20.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.9104\n",
      "INFO:tensorflow:loss = 0.0002964595, step = 15082 (20.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.79587\n",
      "INFO:tensorflow:loss = 0.018601116, step = 15182 (20.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.84616\n",
      "INFO:tensorflow:loss = 0.0011330375, step = 15282 (20.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.9472\n",
      "INFO:tensorflow:loss = 0.004491433, step = 15382 (20.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.7942\n",
      "INFO:tensorflow:loss = 0.0015471281, step = 15482 (20.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.68529\n",
      "INFO:tensorflow:loss = 0.0019927379, step = 15582 (21.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34184\n",
      "INFO:tensorflow:loss = 0.0006624373, step = 15682 (23.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26097\n",
      "INFO:tensorflow:loss = 0.00048802764, step = 15782 (23.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.59224\n",
      "INFO:tensorflow:loss = 0.004169205, step = 15882 (21.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.55303\n",
      "INFO:tensorflow:loss = 0.00074789976, step = 15982 (21.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48783\n",
      "INFO:tensorflow:loss = 0.020610753, step = 16082 (22.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73678\n",
      "INFO:tensorflow:loss = 0.011916983, step = 16182 (21.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.54878\n",
      "INFO:tensorflow:loss = 0.00059522875, step = 16282 (21.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73406\n",
      "INFO:tensorflow:loss = 0.00083361723, step = 16382 (21.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.63995\n",
      "INFO:tensorflow:loss = 0.0010936357, step = 16482 (21.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.51922\n",
      "INFO:tensorflow:loss = 0.00048043494, step = 16582 (22.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.44261\n",
      "INFO:tensorflow:loss = 0.011429109, step = 16682 (22.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.77548\n",
      "INFO:tensorflow:loss = 0.00024952195, step = 16782 (20.940 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16878 into ./checkpoint/rnn\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 4.44616\n",
      "INFO:tensorflow:loss = 0.09649841, step = 16882 (22.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.80103\n",
      "INFO:tensorflow:loss = 0.0020753336, step = 16982 (20.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.71228\n",
      "INFO:tensorflow:loss = 0.0018735135, step = 17082 (21.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.58462\n",
      "INFO:tensorflow:loss = 0.0004673156, step = 17182 (21.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.67519\n",
      "INFO:tensorflow:loss = 0.00051498576, step = 17282 (21.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.74743\n",
      "INFO:tensorflow:loss = 0.00034676568, step = 17382 (21.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45574\n",
      "INFO:tensorflow:loss = 0.0007409053, step = 17482 (22.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.91899\n",
      "INFO:tensorflow:loss = 0.00091696007, step = 17582 (20.329 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.01766\n",
      "INFO:tensorflow:loss = 0.0014738203, step = 17682 (19.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.02497\n",
      "INFO:tensorflow:loss = 0.0014763576, step = 17782 (19.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.03736\n",
      "INFO:tensorflow:loss = 0.0004722542, step = 17882 (19.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.03356\n",
      "INFO:tensorflow:loss = 0.16078313, step = 17982 (19.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.02875\n",
      "INFO:tensorflow:loss = 0.0005613648, step = 18082 (19.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.03407\n",
      "INFO:tensorflow:loss = 0.0061447457, step = 18182 (19.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.03002\n",
      "INFO:tensorflow:loss = 0.00035396143, step = 18282 (19.881 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18302 into ./checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.058712885.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x2a2fe9bdb88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-24T04:33:08Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/rnn\\model.ckpt-18302\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-24-04:33:12\n",
      "INFO:tensorflow:Saving dict for global step 18302: acc = 0.8576, global_step = 18302, loss = 0.7935023\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18302: ./checkpoint/rnn\\model.ckpt-18302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8576, 'loss': 0.7935023, 'global_step': 18302}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data = np.load(open('./data/test_input.npy','rb'))\n",
    "test_id = np.load(open('./data/test_id.npy','rb'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_fn2(X):\n",
    "    inputs = {'x':X}\n",
    "    return inputs\n",
    "\n",
    "def test_input_fn2():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((test_input_data))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(mapping_fn2)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/rnn\\model.ckpt-18302\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "prediction=np.array([p['sentiment'] for p in est.predict(test_input_fn2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제출하기위한 파일 생성\n",
    "output=pd.DataFrame(data={'id':test_id, 'sentiment':list(prediction)})\n",
    "output.to_csv('./data/rnn_predic.csv',index=False,quoting=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
